{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as snd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from poutyne.framework import Model\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "fold = Path.home() / 'Music' / 'Ardour' / 'CNN Training Data' / 'interchange' / 'CNN Training Data' / 'audiofiles'\n",
    "x = snd.read(fold / 'Raw Guitar-1.wav')[0]\n",
    "y = snd.read(fold / 'Orange Amp Heavy-1.wav')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_plot(x, n=1000):\n",
    "    from scipy.ndimage.morphology import grey_dilation, grey_erosion\n",
    "    m = max(1,len(x)//n)\n",
    "    xmax = grey_dilation(x, size=m)[::m]\n",
    "    xmin = grey_erosion (x, size=m)[::m]\n",
    "    rng = np.arange(0,len(x),m)\n",
    "    return [go.Scatter(x=rng, y=xmin, mode='lines', fill=None, line_color='indigo'), go.Scatter(x=rng, y=xmax, mode='lines', fill='tonexty', line_color='indigo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092908575a7d4eaea9cb38ee7e9f978a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'indigo'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "go.FigureWidget(data=audio_plot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f4f508bfdc4ab0b972984889581971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'indigo'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "go.FigureWidget(data=audio_plot(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "class StackedNet(nn.Module):\n",
    "    def __init__(self, layer_width, n_layers):\n",
    "        super().__init__()\n",
    "        self.layer_width = layer_width\n",
    "        self.n_layers = n_layers\n",
    "        pw = 1\n",
    "        i = 0\n",
    "        self.layers = []\n",
    "        for d in range(n_layers):\n",
    "            d = floor(2**d)\n",
    "            self.layers += [nn.Sequential(\n",
    "                nn.Conv1d(pw, layer_width, kernel_size=3, dilation=d, padding=d),\n",
    "                nn.ReLU()\n",
    "            )]\n",
    "            pw = layer_width\n",
    "            i += layer_width\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.olayer = nn.Conv1d(i,1,kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xl = [x]\n",
    "        for l in self.layers:\n",
    "            xl += [l(xl[-1])]\n",
    "        return self.olayer(torch.cat(xl[1:], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CroppedDataset(Dataset):\n",
    "    def __init__(self, x, y, w):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.w = w\n",
    "        self.l = min(len(x),len(y))-w\n",
    "        assert self.l > 0\n",
    "        self.idx = np.random.permutation(range(self.l))\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        i = self.idx[i]\n",
    "        return self.x[i:i+self.w].reshape(1,-1), self.y[i:i+self.w].reshape(1,-1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poutyne.framework import Callback\n",
    "from IPython.display import display\n",
    "from time import time\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "from math import ceil\n",
    "\n",
    "class Plotter(Callback):\n",
    "    def __init__(self):\n",
    "        self.fig = None\n",
    "        self.data = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.data += [logs['loss']]\n",
    "        if self.fig is None:\n",
    "            ysmooth = median_filter(self.data, ceil(len(self.data)/100))\n",
    "            self.fig = go.FigureWidget(data=[go.Scattergl(y=self.data),go.Scattergl(y=ysmooth)])\n",
    "            display(self.fig)\n",
    "            self.last_t = time()\n",
    "        else:\n",
    "            t = time()\n",
    "            if t - self.last_t > 0.5:\n",
    "                self.fig.data[0].y = self.data\n",
    "                self.fig.data[1].y = median_filter(self.data, ceil(len(self.data)/100))\n",
    "                self.last_t = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "ds = CroppedDataset(x,y[500:], 10000)\n",
    "dl = DataLoader(ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PolySoftPlusFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        r1 = (x<=-0.5)\n",
    "        r2 = (~r1)&(x<0.5)\n",
    "        r1,r2 = torch.nonzero(r1).T,torch.nonzero(r2).T\n",
    "        ctx.save_for_backward(x,r1,r2)\n",
    "        y = x.clone()\n",
    "        r1,r2 = tuple(r1),tuple(r2)\n",
    "        y[r1] = 0\n",
    "        y[r2] = 0.5*(x[r2]+0.5)**2\n",
    "        return y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, g):\n",
    "        x,r1,r2 = ctx.saved_tensors\n",
    "        r1,r2 = tuple(r1), tuple(r2)\n",
    "        go = g.clone()\n",
    "        go[r1] = 0\n",
    "        go[r2] *= x[r2]+0.5\n",
    "        return go\n",
    "\n",
    "class PolySoftPlus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f = PolySoftPlusFunction()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.f.apply(x)\n",
    "        #y = torch.empty_like(x)\n",
    "        #r2 = (x>-0.5)&(x<0.5)\n",
    "        #y[~r2] = F.relu(x[~r2])\n",
    "        #y[r2] = 0.5*(x[r2]+0.5)**2\n",
    "        #return y\n",
    "\n",
    "class StackedNet2(nn.Module):\n",
    "    def __init__(self, layer_width, dilations):\n",
    "        super().__init__()\n",
    "        self.layer_width = layer_width\n",
    "        self.n_layers = len(dilations)\n",
    "        print(dilations)\n",
    "        pw = 1\n",
    "        n = 0\n",
    "        self.layers = []\n",
    "        for d in dilations:\n",
    "            k = min(2,1+d)\n",
    "            self.layers += [\n",
    "                nn.Conv1d(pw, layer_width, kernel_size=k, dilation=max(d,1)),\n",
    "                nn.ReLU(),\n",
    "                #PolySoftPlus(),\n",
    "            ]\n",
    "            n += pw*layer_width*k + layer_width\n",
    "            pw = layer_width\n",
    "        self.layers = nn.Sequential(*self.layers, nn.Conv1d(pw,1,1))\n",
    "        n += pw + 1\n",
    "        print(n, ' parameters')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 128, 64, 32, 16, 8, 4, 2]\n",
      "1511  parameters\n",
      "Epoch 1/1000 ETA 168783s Step 1/11254000: loss: 0.046454"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24114b823557477286c8697524f93434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scattergl', 'uid': 'f67e7e87-4824-45d1-b954-c3f50491775a', 'y': [0.04645…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 ETA 258862s Step 24325/11254000: loss: 0.002140"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-5e232acfd737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, initial_epoch, verbose, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m                     step.loss, step.metrics, _ = self._fit_batch(x, y,\n\u001b[1;32m    311\u001b[0m                                                                  \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                                                                  step=step.number)\n\u001b[0m\u001b[1;32m    313\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36m_fit_batch\u001b[0;34m(self, x, y, callback, step, return_pred)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mloss_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#net = StackedNet2(10, 2**np.arange(10))\n",
    "#net = StackedNet2(8, 2**np.arange(1,10))\n",
    "#net = StackedNet2(8, 2**np.arange(10))\n",
    "#net = StackedNet2(8, [100,110,120,130,140,150,160,170,180,190])\n",
    "#net = StackedNet2(3, np.arange(50,100,10))\n",
    "#net = StackedNet2(5, [0,0,0,60,70,80,90,100,0,0,0])\n",
    "#net = StackedNet2(5,[1,2,4,8,16,32,64])\n",
    "\n",
    "def trunc_mse(ytrue,y):\n",
    "    m = min(ytrue.shape[-1],y.shape[-1])\n",
    "    return torch.mean((ytrue[:,:,-m:]-y[:,:,-m:])**2)\n",
    "\n",
    "#net = StackedNet2(10, np.arange(100,200,10))\n",
    "primes = [101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211]\n",
    "#net = StackedNet2(10,[101,131,167,181,211])\n",
    "#net = StackedNet2(4,[8,16,32,64,128,256])\n",
    "#net = StackedNet2(4,[8,16,32,150])\n",
    "#net = StackedNet2(7,[8,16,32,64,128,256])\n",
    "#net = StackedNet2(10,[8,16,32,64,128,256])\n",
    "net = StackedNet2(10,list(reversed([2,4,8,16,32,64,128,256])))\n",
    "#net = StackedNet2(30,[128,64,32,16,8,256,128,64,32,16])\n",
    "\n",
    "l1loss = nn.L1Loss()\n",
    "\n",
    "def reg_loss(ytrue,y):\n",
    "    return trunc_mse(ytrue,y) + 0.005*sum(l1loss(p,torch.zeros_like(p)) for p in net.parameters())\n",
    "\n",
    "model = Model(net, AdamW(net.parameters()), trunc_mse)\n",
    "\n",
    "model.fit_generator(dl, callbacks=[Plotter()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab101acffeb74fe5abe445d380093ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'indigo'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtest = x[1010000:1014000]\n",
    "go.FigureWidget(data=audio_plot(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea20313e6e754ee1bd2d152479f56d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'indigo'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrue = y[800:][1010000:1014000]\n",
    "go.FigureWidget(data=audio_plot(ytrue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcacbf02b9140aead95aa2979c0ba10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'indigo'},\n",
       "              'mode': 'lines',\n",
       "              'type':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xpred = model.predict_on_batch(torch.FloatTensor(xtest).reshape(1,1,-1))[0,0]\n",
    "go.FigureWidget(data=audio_plot(xpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(p) for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11e6c102b704a92ba5215e8dc371a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines',\n",
       "              'type': 'scatter',\n",
       "              'uid': '16cf30d7-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "go.FigureWidget(data=[go.Scatter(y=l.weight.detach().numpy().ravel(), mode='lines') for l in net.layers if hasattr(l,'weight')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c565b1d6a32b4cf5addd996fac0c8256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'heatmap',\n",
       "              'uid': 'f975ec9f-9a2d-4caf-8148-f7c53cd3c029',\n",
       " …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "go.FigureWidget(data=[go.Heatmap(z=net.layers[8].weight.detach().numpy()[:,:,0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! It works! We can train a neural network to function as a drop-in replacement for distortion. This is really fascinating....\n",
    "\n",
    "Now, time to generate code to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_str(m):\n",
    "    if len(m.shape) == 0:\n",
    "        return str(m.item())\n",
    "    else:\n",
    "        return '{' + ','.join(mat_to_str(mi) for mi in m) + '}'\n",
    "    \n",
    "def layer_to_str(layer, name, xi, xo, latency):\n",
    "    m = layer.in_channels\n",
    "    n = layer.out_channels\n",
    "    d, = layer.dilation\n",
    "    k, = layer.kernel_size\n",
    "\n",
    "    def join(s,l,j,e):\n",
    "        return s + j.join(str(li) for li in l) + e\n",
    "\n",
    "    #weights = mat_to_str(layer.weight)\n",
    "    weights = mat_to_str(np.moveaxis(layer.weight.detach().numpy(),2,0))\n",
    "    bias = mat_to_str(layer.bias)\n",
    "\n",
    "    r = f\"\"\"\n",
    "    // auto-generated code for layer {name}: {layer}\n",
    "    const float w_{name}[{n}][{m}][{k}] = {weights};\n",
    "    const float b_{name}[{n}] = {bias};\n",
    "    \n",
    "    // Fill with biases for {name}\n",
    "    for (int i = 0; i < {n}; i++) {{\n",
    "        float bi = b_{name}[i];\n",
    "        for (int l = {latency}; l < L; l++) {{\n",
    "            {xo}[i][l] = bi;\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    // Apply main filter for {name}\n",
    "    for (int i = 0; i < {n}; i++){{\n",
    "        for (int j = 0; j < {m}; j++){{\n",
    "            for (int k = 0; k < {k}; k++) {{\n",
    "                float wijk = w_{name}[i][j][k];\n",
    "                int offset = ({k-1}-k)*{d};\n",
    "                for (int l = {latency}; l < L; l++){{\n",
    "                    {xo}[i][l] += wijk * {xi}[j][l-offset];\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    r = f\"\"\"\n",
    "    // auto-generated code for layer {name}: {layer}\n",
    "    const float w_{name}[{k}][{n}][{m}] = {weights};\n",
    "    const float b_{name}[{n}] = {bias};\n",
    "    \n",
    "    // Fill with biases for {name}\n",
    "    for (int i = 0; i < {n}; i++) {{\n",
    "        for (int l = {latency}; l < L; l++) {{\n",
    "            {xo}[i][l] = b_{name}[i];\n",
    "        }}\n",
    "    }}\n",
    "    \n",
    "    // Apply main filter for {name}\n",
    "    // {xo}[:,{latency}:] = sum(w[k]@{xi}[:,{latency}-({k-1}-k)*{d}:L-({k-1}-k)*{d}] for k in w.shape[0])\n",
    "    for (int k = 0; k < {k}; k++) {{\n",
    "        int offset = ({k-1}-k)*{d};\n",
    "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, {n}, L-{latency}, {m}, 1.0, &w_{name}[k][0][0], {m}, &{xi}[0][{latency}-offset], MAX_L, 1.0, &{xo}[0][{latency}], MAX_L);\n",
    "    }}\n",
    "    \n",
    "    \"\"\"\n",
    "    return r\n",
    "\n",
    "def relu_to_str(size,xi,xo,latency):\n",
    "    r = f\"\"\"\n",
    "    // Rectified Linear Unit (ReLU)\n",
    "    for (int i = 0; i < {size}; i++) {{\n",
    "        for (int l = {latency}; l < L; l++) {{\n",
    "            {xo}[i][l] = {xi}[i][l] > 0 ? {xi}[i][l] : 0;\n",
    "        }}\n",
    "    }}\n",
    "\n",
    "    \"\"\"\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_to_str(seq):\n",
    "    \n",
    "    #r = \"\"\"void apply_cnn(float* x, float* y, int L) {\n",
    "    #float* xin[1] = {x};\n",
    "    #\"\"\"\n",
    "    \n",
    "    max_w = max(l.out_channels for l in seq if hasattr(l,'out_channels'))\n",
    "    latency = sum((l.kernel_size[0]-1)*l.dilation[0] for l in seq if hasattr(l,'out_channels'))\n",
    "    \n",
    "    #r += f\"\"\"\n",
    "    #float x_even[{max_w}][L];\n",
    "    #float x_odd [{max_w}][L];\n",
    "    #\"\"\"\n",
    "    \n",
    "    r = f\"\"\"\n",
    "extern \"C\" {{\n",
    "#include <cblas.h>\n",
    "}};\n",
    "\n",
    "// About {max_w*2*(8192+latency)/1e6} MB\n",
    "const int latency = {latency};\n",
    "const int MAX_L = {8192+latency};\n",
    "float x_even[{max_w}][MAX_L];\n",
    "float x_odd [{max_w}][MAX_L];\n",
    "\n",
    "void apply_cnn(float* x, float* y, int L) {{\n",
    "\n",
    "    // Ensure we don't segfault\n",
    "    L = L > MAX_L ? MAX_L : L;\n",
    "    \n",
    "    for (int i = 0; i < L; i++) {{\n",
    "        x_odd[0][i] = x[i];\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    s = None\n",
    "    i = 0\n",
    "    latency = 0\n",
    "    xevenodd = [\"x_even\",\"x_odd\"]\n",
    "    xi = xevenodd[1]\n",
    "    for l in seq:\n",
    "        if isinstance(l, nn.ReLU):\n",
    "            r += relu_to_str(s,xi,xi,latency)\n",
    "        else:\n",
    "            latency += (l.kernel_size[0]-1)*l.dilation[0]\n",
    "            #xo = f\"x{i}\"\n",
    "            xo = xevenodd[i%2]\n",
    "            r += layer_to_str(l,f\"layer_{i}\",xi,xo,latency)\n",
    "            s = l.out_channels\n",
    "            i += 1\n",
    "            xi = xo\n",
    "    r += f\"\"\"\n",
    "    // Copy result back to y\n",
    "    for (int l = {latency}; l < L; l++) {{\n",
    "        y[l] = {xo}[0][l];\n",
    "    }}\n",
    "}}\n",
    "    \"\"\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "extern \"C\" {\n",
      "#include <cblas.h>\n",
      "};\n",
      "\n",
      "// About 0.121744 MB\n",
      "const int latency = 504;\n",
      "const int MAX_L = 8696;\n",
      "float x_even[7][MAX_L];\n",
      "float x_odd [7][MAX_L];\n",
      "\n",
      "void apply_cnn(float* x, float* y, int L) {\n",
      "\n",
      "    // Ensure we don't segfault\n",
      "    L = L > MAX_L ? MAX_L : L;\n",
      "    \n",
      "    for (int i = 0; i < L; i++) {\n",
      "        x_odd[0][i] = x[i];\n",
      "    }\n",
      "    \n",
      "    // auto-generated code for layer layer_0: Conv1d(1, 7, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
      "    const float w_layer_0[2][7][1] = {{{0.43975532054901123},{-0.9576542973518372},{-0.7286499738693237},{-0.37760645151138306},{0.6205844879150391},{0.8448692560195923},{0.1774430125951767}},{{0.13842950761318207},{-0.4070027768611908},{-0.18621504306793213},{0.006337991915643215},{-0.39210474491119385},{0.13554632663726807},{-0.6126473546028137}}};\n",
      "    const float b_layer_0[7] = {0.20157429575920105,-0.09349554777145386,-0.2968412935733795,1.174821138381958,1.1558347940444946,0.07309959083795547,0.02421138435602188};\n",
      "    \n",
      "    // Fill with biases for layer_0\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 8; l < L; l++) {\n",
      "            x_even[i][l] = b_layer_0[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_0\n",
      "    // x_even[:,8:] = sum(w[k]@x_odd[:,8-(1-k)*8:L-(1-k)*8] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*8;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-8, 1, 1.0, &w_layer_0[k][0][0], 1, &x_odd[0][8-offset], MAX_L, 1.0, &x_even[0][8], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 8; l < L; l++) {\n",
      "            x_even[i][l] = x_even[i][l] > 0 ? x_even[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_1: Conv1d(7, 7, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
      "    const float w_layer_1[2][7][7] = {{{-0.047680456191301346,0.22598043084144592,0.04223530739545822,0.015184814110398293,-0.0032753772102296352,0.006486369762569666,-0.08449392765760422},{0.14121240377426147,0.1361805498600006,-0.17172017693519592,0.23677413165569305,0.043277423828840256,-0.009546427987515926,0.008683811873197556},{-0.06872459501028061,0.4176238179206848,0.30801302194595337,0.23419582843780518,-0.2061547189950943,-0.09992019832134247,-0.14349795877933502},{0.3183206021785736,-0.11453276127576828,-0.06131158396601677,0.08914864808320999,0.2647489905357361,0.42979806661605835,0.3393782675266266},{0.5139473080635071,0.04650144651532173,-0.2049339860677719,0.2960723042488098,0.08609504997730255,0.3637298047542572,0.1408432573080063},{0.48300740122795105,-0.035698406398296356,0.015724148601293564,0.030072741210460663,0.11047107726335526,0.19377604126930237,-0.04796731844544411},{-0.24829211831092834,0.27624452114105225,0.39692890644073486,0.4465985596179962,-0.0559021420776844,-0.05823681131005287,0.1720779985189438}},{{0.11114673316478729,0.004014292731881142,-0.07314734905958176,0.16126111149787903,-0.14846374094486237,-0.0036441602278500795,-0.4734152853488922},{0.103895403444767,0.0075261835008859634,0.047215547412633896,-0.25768348574638367,0.22607125341892242,0.29493072628974915,-0.25760817527770996},{0.26382556557655334,0.06722670048475266,0.32075050473213196,0.3065233528614044,0.10986650735139847,0.262722909450531,0.03961135819554329},{0.12434373050928116,0.19310036301612854,0.2663846015930176,0.21694333851337433,-0.13702259957790375,-0.12745091319084167,-0.10604656487703323},{0.24453769624233246,-0.21774564683437347,-0.033199939876794815,0.18092378973960876,0.5253491997718811,0.4624098539352417,0.04320145770907402},{0.22027049958705902,-0.1572887897491455,0.2334461659193039,0.005792610347270966,0.11644211411476135,0.38686954975128174,0.1549401730298996},{0.1776304692029953,0.10877832770347595,0.33355581760406494,0.12424486130475998,0.19953610002994537,0.09312401711940765,-0.09673220664262772}}};\n",
      "    const float b_layer_1[7] = {-0.014528545551002026,-0.10937076807022095,0.4903193712234497,0.36090660095214844,0.5221177339553833,-0.1397244781255722,0.2671821415424347};\n",
      "    \n",
      "    // Fill with biases for layer_1\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 24; l < L; l++) {\n",
      "            x_odd[i][l] = b_layer_1[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_1\n",
      "    // x_odd[:,24:] = sum(w[k]@x_even[:,24-(1-k)*16:L-(1-k)*16] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*16;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-24, 7, 1.0, &w_layer_1[k][0][0], 7, &x_even[0][24-offset], MAX_L, 1.0, &x_odd[0][24], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 24; l < L; l++) {\n",
      "            x_odd[i][l] = x_odd[i][l] > 0 ? x_odd[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_2: Conv1d(7, 7, kernel_size=(2,), stride=(1,), dilation=(32,))\n",
      "    const float w_layer_2[2][7][7] = {{{0.06280938535928726,-0.01815027929842472,0.3623906075954437,-0.1463266909122467,-0.06213067099452019,-0.1197378933429718,0.46197885274887085},{-0.09041408449411392,-0.10934095084667206,0.19107452034950256,0.19606518745422363,0.18783682584762573,0.010249525308609009,-0.07739142328500748},{-0.14067280292510986,-0.24763168394565582,-0.07483064383268356,-0.0925685241818428,-0.04229846969246864,-0.13334167003631592,-0.1236184760928154},{-0.0991448312997818,-0.20878693461418152,0.05082370713353157,0.2850457727909088,0.19940030574798584,0.23660606145858765,0.040846087038517},{0.1936768889427185,-0.015861833468079567,0.42659732699394226,-0.46782833337783813,0.17113517224788666,-0.10946584492921829,0.44017601013183594},{-0.05167343467473984,0.06182600185275078,-0.16180852055549622,0.5753205418586731,0.26157280802726746,0.2610684037208557,-0.11078200489282608},{0.17350061237812042,0.3750641644001007,-0.023184817284345627,-0.04247882217168808,0.30530259013175964,0.05756421014666557,-0.018971707671880722}},{{-0.04611368477344513,0.17550291121006012,0.13100779056549072,-0.0034649972803890705,0.11453231424093246,0.027286548167467117,0.2959210276603699},{0.2411370575428009,-0.09391191601753235,0.19332964718341827,0.2496001422405243,-0.11455328017473221,-0.30635663866996765,0.28041884303092957},{0.008350208401679993,0.08266369998455048,-0.29513412714004517,0.2887708246707916,-0.08055488765239716,-0.05126958340406418,0.17993301153182983},{-0.05761681869626045,0.3300707936286926,0.05895606055855751,-0.4388279914855957,0.49367743730545044,0.3303913176059723,-0.05152357742190361},{0.05874111130833626,-0.23516657948493958,0.06804130971431732,0.14868493378162384,0.2826744318008423,0.03298449143767357,0.18283811211585999},{0.05614101141691208,-0.11788848042488098,0.16896969079971313,0.26538360118865967,-0.04920175299048424,-0.16026483476161957,0.24448128044605255},{0.02046843431890011,-0.04610493406653404,-0.05089070647954941,-0.06182149052619934,0.5230814218521118,0.2950809895992279,-0.033358313143253326}}};\n",
      "    const float b_layer_2[7] = {0.2359328716993332,0.05900083854794502,-0.026605919003486633,0.058036528527736664,0.41392892599105835,0.31958985328674316,0.4536774754524231};\n",
      "    \n",
      "    // Fill with biases for layer_2\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 56; l < L; l++) {\n",
      "            x_even[i][l] = b_layer_2[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_2\n",
      "    // x_even[:,56:] = sum(w[k]@x_odd[:,56-(1-k)*32:L-(1-k)*32] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*32;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-56, 7, 1.0, &w_layer_2[k][0][0], 7, &x_odd[0][56-offset], MAX_L, 1.0, &x_even[0][56], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 56; l < L; l++) {\n",
      "            x_even[i][l] = x_even[i][l] > 0 ? x_even[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_3: Conv1d(7, 7, kernel_size=(2,), stride=(1,), dilation=(64,))\n",
      "    const float w_layer_3[2][7][7] = {{{0.23653383553028107,0.24479833245277405,0.38706541061401367,-0.21954146027565002,0.24404774606227875,0.4421163499355316,-0.28491947054862976},{0.23272880911827087,-0.009002293460071087,-0.19093570113182068,0.24945561587810516,0.09847501665353775,-0.1676730215549469,0.04687301442027092},{0.1836053878068924,-0.09488405287265778,-0.038463130593299866,0.4660724997520447,0.016205476596951485,-0.00768674723803997,0.48629677295684814},{0.056353166699409485,0.012449345551431179,0.00030654791044071317,-0.09045202285051346,0.16330568492412567,0.17861855030059814,0.06313570588827133},{0.0396851971745491,-0.08792261779308319,0.07455498725175858,0.01304593589156866,0.12239404022693634,0.17643354833126068,0.11669289320707321},{0.16583196818828583,0.33560237288475037,0.39387887716293335,-0.2836248278617859,0.2677428126335144,0.1402679830789566,-0.0632123351097107},{-0.06888031959533691,0.16902773082256317,0.12492423504590988,-0.09193205088376999,0.002234019571915269,0.1899285465478897,0.1898403912782669}},{{-0.08398184180259705,0.19504790008068085,0.4858488142490387,0.008688298985362053,-0.08405569940805435,0.43827423453330994,0.12489353120326996},{0.026188073679804802,-0.18213963508605957,0.3539673089981079,0.008892614394426346,0.10420901328325272,0.03119570203125477,0.03193189948797226},{0.37262165546417236,0.1849861741065979,0.24036474525928497,-0.11782591044902802,0.47698038816452026,-0.2846500277519226,-0.12930890917778015},{-0.0666830986738205,0.13907290995121002,-0.17100889980793,0.1594831645488739,-0.22791893780231476,0.4691983461380005,-0.12429986894130707},{-0.2417566180229187,-0.2881883382797241,0.3205164074897766,0.14949601888656616,0.1638515144586563,0.27659955620765686,0.47857198119163513},{0.027067186310887337,0.002163609489798546,-0.02681700326502323,0.1978711038827896,-0.2167036384344101,0.3055853545665741,0.08343293517827988},{-0.20340058207511902,0.0572643019258976,-0.5260995626449585,0.10784050822257996,-0.037853047251701355,0.1485191136598587,0.14898967742919922}}};\n",
      "    const float b_layer_3[7] = {0.023768840357661247,-0.28494444489479065,0.30037713050842285,0.12269607931375504,0.34050002694129944,0.13255788385868073,-0.0925801545381546};\n",
      "    \n",
      "    // Fill with biases for layer_3\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 120; l < L; l++) {\n",
      "            x_odd[i][l] = b_layer_3[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_3\n",
      "    // x_odd[:,120:] = sum(w[k]@x_even[:,120-(1-k)*64:L-(1-k)*64] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*64;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-120, 7, 1.0, &w_layer_3[k][0][0], 7, &x_even[0][120-offset], MAX_L, 1.0, &x_odd[0][120], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 120; l < L; l++) {\n",
      "            x_odd[i][l] = x_odd[i][l] > 0 ? x_odd[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_4: Conv1d(7, 7, kernel_size=(2,), stride=(1,), dilation=(128,))\n",
      "    const float w_layer_4[2][7][7] = {{{0.30637916922569275,0.08116886019706726,0.01636119931936264,-0.009075069800019264,0.21599361300468445,-9.370451880386099e-05,-0.1386367529630661},{-0.21605359017848969,0.18836379051208496,0.06778044998645782,-0.01783696934580803,0.0535116046667099,-0.1709488481283188,-0.08294395357370377},{0.06032118946313858,-0.22404921054840088,0.13581717014312744,0.22341302037239075,0.0005800066865049303,0.1399070918560028,0.15878722071647644},{0.13364660739898682,0.005663950927555561,0.18005627393722534,0.08704257011413574,0.31483718752861023,0.05395768582820892,0.3402180075645447},{0.15779322385787964,-0.11168143153190613,0.14440922439098358,0.23949341475963593,-0.18300534784793854,-0.1245456263422966,0.13017448782920837},{0.006449013017117977,-0.05411409214138985,0.1023489385843277,0.1410597711801529,0.04657697305083275,0.008248954080045223,0.07869412750005722},{-0.07852944731712341,-0.1557716727256775,0.22023484110832214,0.031078342348337173,-0.10715734958648682,-0.029658019542694092,0.15526360273361206}},{{-0.3540179431438446,0.2934146523475647,0.6207103133201599,-0.11733607947826385,0.16273067891597748,-0.16120800375938416,-0.13479086756706238},{-0.058497603982686996,-0.2115447223186493,-0.08519284427165985,-0.18489645421504974,-0.20549717545509338,-0.1852150410413742,0.12548622488975525},{0.2906762361526489,-0.0872352197766304,-0.14502736926078796,0.30741533637046814,-0.16186489164829254,0.18880602717399597,-0.1275937557220459},{0.30014434456825256,0.20653647184371948,-0.074044369161129,0.15109053254127502,0.314430832862854,0.3310824930667877,0.12222786247730255},{0.2266242653131485,0.10877527296543121,-0.30016663670539856,0.2762288451194763,0.20071937143802643,0.3429868817329407,-0.09899087995290756},{-0.09691740572452545,0.1516733169555664,-0.21236371994018555,0.26805561780929565,0.32679304480552673,0.10029784590005875,0.36802440881729126},{0.07843716442584991,-0.021788321435451508,0.01030885148793459,-0.03842708840966225,-0.10314967483282089,0.3624880611896515,-0.02774372510612011}}};\n",
      "    const float b_layer_4[7] = {0.2513434886932373,-0.1389145404100418,0.3085789680480957,0.2764591872692108,0.21824561059474945,-0.07348572462797165,0.22931928932666779};\n",
      "    \n",
      "    // Fill with biases for layer_4\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 248; l < L; l++) {\n",
      "            x_even[i][l] = b_layer_4[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_4\n",
      "    // x_even[:,248:] = sum(w[k]@x_odd[:,248-(1-k)*128:L-(1-k)*128] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*128;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-248, 7, 1.0, &w_layer_4[k][0][0], 7, &x_odd[0][248-offset], MAX_L, 1.0, &x_even[0][248], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 248; l < L; l++) {\n",
      "            x_even[i][l] = x_even[i][l] > 0 ? x_even[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_5: Conv1d(7, 7, kernel_size=(2,), stride=(1,), dilation=(256,))\n",
      "    const float w_layer_5[2][7][7] = {{{-0.2229795902967453,-0.16370558738708496,-0.11687512695789337,-0.043522562831640244,-0.0827605202794075,-0.2285250872373581,-0.003623856930062175},{0.019918950274586678,0.0912233516573906,0.2800306975841522,0.02587067149579525,-0.09818439930677414,-0.3159421384334564,0.21988599002361298},{-0.12503112852573395,-0.03398310765624046,0.12354888021945953,-0.0075157200917601585,0.12361589074134827,-0.1970783919095993,-0.17289741337299347},{0.09904017299413681,-0.15137849748134613,-0.09117397665977478,0.1965809166431427,0.09651871025562286,-0.3521946668624878,0.24201636016368866},{-0.12499682605266571,-0.08784890174865723,-0.11941858381032944,0.07415889203548431,-0.14694151282310486,0.0892610028386116,-0.17267493903636932},{-0.05364137515425682,-0.0792326107621193,0.21461601555347443,0.25730571150779724,0.20398205518722534,-0.17697350680828094,-0.14029139280319214},{0.04627688601613045,0.008397537283599377,-0.02041180431842804,0.3550931215286255,-0.03792072460055351,0.16159923374652863,-0.007434195838868618}},{{-0.22624173760414124,0.04849760979413986,-0.055094651877880096,-0.20517262816429138,-0.21005262434482574,-0.15078912675380707,0.005034912843257189},{0.5252518653869629,-0.2204846739768982,-0.04515289515256882,0.168263778090477,-0.25762316584587097,-0.2588098645210266,0.17278504371643066},{0.05263124406337738,0.03786877915263176,0.08170673996210098,-0.26301348209381104,0.04202592000365257,-0.09411013871431351,0.05623424053192139},{0.34524932503700256,0.19618649780750275,-0.23784354329109192,-0.050279222428798676,-0.07520925998687744,-0.2856491208076477,0.14391718804836273},{-0.01803538016974926,0.09888104349374771,-0.010810544714331627,-0.204018697142601,-0.07880788296461105,-0.10840117186307907,-0.19747400283813477},{0.38586747646331787,-0.1005222350358963,0.07431892305612564,-0.10150257498025894,-0.030801789835095406,-0.1591787040233612,-0.22678759694099426},{-0.39117366075515747,-0.17810207605361938,0.432077020406723,0.35984107851982117,0.3642406761646271,0.08280185610055923,0.2891467809677124}}};\n",
      "    const float b_layer_5[7] = {-0.22563466429710388,0.31531426310539246,-0.04540131613612175,0.27710530161857605,0.006135811097919941,0.0720251277089119,0.16606023907661438};\n",
      "    \n",
      "    // Fill with biases for layer_5\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 504; l < L; l++) {\n",
      "            x_odd[i][l] = b_layer_5[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_5\n",
      "    // x_odd[:,504:] = sum(w[k]@x_even[:,504-(1-k)*256:L-(1-k)*256] for k in w.shape[0])\n",
      "    for (int k = 0; k < 2; k++) {\n",
      "        int offset = (1-k)*256;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 7, L-504, 7, 1.0, &w_layer_5[k][0][0], 7, &x_even[0][504-offset], MAX_L, 1.0, &x_odd[0][504], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Rectified Linear Unit (ReLU)\n",
      "    for (int i = 0; i < 7; i++) {\n",
      "        for (int l = 504; l < L; l++) {\n",
      "            x_odd[i][l] = x_odd[i][l] > 0 ? x_odd[i][l] : 0;\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n",
      "    // auto-generated code for layer layer_6: Conv1d(7, 1, kernel_size=(1,), stride=(1,))\n",
      "    const float w_layer_6[1][1][7] = {{{-0.16930052638053894,-0.48942217230796814,0.06773407012224197,-0.22754520177841187,-0.07698748260736465,-0.2099757343530655,0.2950187623500824}}};\n",
      "    const float b_layer_6[1] = {0.22056184709072113};\n",
      "    \n",
      "    // Fill with biases for layer_6\n",
      "    for (int i = 0; i < 1; i++) {\n",
      "        for (int l = 504; l < L; l++) {\n",
      "            x_even[i][l] = b_layer_6[i];\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    // Apply main filter for layer_6\n",
      "    // x_even[:,504:] = sum(w[k]@x_odd[:,504-(0-k)*1:L-(0-k)*1] for k in w.shape[0])\n",
      "    for (int k = 0; k < 1; k++) {\n",
      "        int offset = (0-k)*1;\n",
      "        cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasNoTrans, 1, L-504, 7, 1.0, &w_layer_6[k][0][0], 7, &x_odd[0][504-offset], MAX_L, 1.0, &x_even[0][504], MAX_L);\n",
      "    }\n",
      "    \n",
      "    \n",
      "    // Copy result back to y\n",
      "    for (int l = 504; l < L; l++) {\n",
      "        y[l] = x_even[0][l];\n",
      "    }\n",
      "}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "s = sequential_to_str(net.layers)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = \"\"\"\n",
    "#include <iostream>\n",
    "#include <chrono>\n",
    "int main() {\n",
    "        int N = 1000;\n",
    "        auto now = std::chrono::high_resolution_clock::now;\n",
    "        float x[N];\n",
    "        float y[N];\n",
    "        for (int i = 0; i < N; i++) {\n",
    "            x[i] = rand();\n",
    "        }\n",
    "        auto start = now();\n",
    "        for (int i = 0; i < 1000; i++) {\n",
    "            apply_cnn(x,y,N);\n",
    "        }\n",
    "        auto end = now();\n",
    "        std::cout << 100*std::chrono::duration<double>(end-start).count()/1000/(N-504)*96e3 << \"%\" << std::endl;\n",
    "}\n",
    "\"\"\"\n",
    "with open('/tmp/test.cpp', 'w') as f:\n",
    "    f.write(s+main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -O3 /tmp/test.cpp -o /tmp/test -lopenblas -L/usr/lib64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.82049%\n"
     ]
    }
   ],
   "source": [
    "!/tmp/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bam! Sub 2% of the CPU usage. That's really good. With 4 CPUs, it's even less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/torch/serialization.py:292: UserWarning:\n",
      "\n",
      "Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "\n",
      "/usr/local/lib64/python3.7/site-packages/torch/serialization.py:292: UserWarning:\n",
      "\n",
      "Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
      "\n",
      "/usr/local/lib64/python3.7/site-packages/torch/serialization.py:292: UserWarning:\n",
      "\n",
      "Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.layers, '/home/michael/Other/code/cnn_distortion/models/cnn_dist_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
